# -*- coding: utf-8 -*-
"""parkinsons_disease_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11HFXgboGwYVP90ZYJjKwaJm1QilxTeAQ

importing dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

"""data collection and analysis

loading data from csv file to pandas dataframe


"""

parkinsons_data=pd.read_csv('parkinsons.csv')

"""first 5 data from dataset"""

parkinsons_data.head()

"""total rows and cols"""

parkinsons_data.shape

"""total items in dataset"""

parkinsons_data.count()

"""more information"""

parkinsons_data.info()

"""any missing values?"""

parkinsons_data.isnull().sum()

"""getting statistical measures about data"""

parkinsons_data.describe()

"""distribution of target variable ie status of healthy or parkinsons"""

parkinsons_data['status'].value_counts()

"""0 --> parkinson's negative ;
1 --> parkinson's positive

grouping data based on status (target variable)
"""

parkinsons_data.groupby('status').mean()

"""data preprocessing

separating features and target
"""

x=parkinsons_data.drop(columns=['name','status'],axis=1)
y=parkinsons_data['status']

#print(x)

#print(y)

"""splitting data as training and test data

splitting and storing data into array
"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=2)

print(x.shape,x_train.shape,x_test.shape)

"""data standardization"""

scaler=StandardScaler()

scaler.fit(x_train)

"""transforming to standard"""

x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

print(x_train)

"""training the model with data"""

model=svm.SVC(kernel='linear')

"""training model with training data"""

model.fit(x_train,y_train)

"""model evaluation and finding accuracy score

accuracy score on training data
"""

x_train_prediction=model.predict(x_train)
training_data_accuracy=accuracy_score(y_train,x_train_prediction)

print('Accuracy score of training data',training_data_accuracy)

x_test_prediction=model.predict(x_test)
testing_data_accuracy=accuracy_score(y_test,x_test_prediction)

print('Accuracy score of testing data',testing_data_accuracy)

"""building an predictive system

giving random data as input and convert it into numpy array
"""

input_data=(176.17000,185.60400,163.56400,0.00369,0.00002,0.00205,0.00218,0.00616,0.01851,0.16800,0.00938,0.01160,0.01491,0.02814,0.00340,24.95100,0.341435,0.783626,-6.006414,0.196371,2.536527,0.173218
)
input_data_as_numpy_array=np.asarray(input_data)

"""reshape the numpy array --> to tell that prediction is for only one data to model"""

input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)

"""standardize the input data"""

std_data=scaler.transform(input_data_reshaped)

"""predicting parkinsons for user data"""

model_prediction=model.predict(std_data)
print(model_prediction)

if(model_prediction[0]==0):
  print('person is healthy and not have parkinsons')
else:
  print('person does have parkinsons')